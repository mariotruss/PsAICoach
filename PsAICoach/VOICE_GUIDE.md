# ğŸ™ï¸ Voice-First PsyCoach Guide

## Overview

PsyCoach now features a **voice-first interface** inspired by modern therapy apps, with a dark teal aesthetic and natural voice conversations.

## ğŸ¨ Design

The voice interface features:
- **Dark Teal Theme**: Calming, professional color palette
- **Voice Orb**: Central interactive element that responds to touch/click
- **Real-time Transcription**: See what you're saying as you speak
- **Action Cards**: Quick options to guide conversations
- **Smooth Animations**: Professional, fluid transitions

## ğŸ¤ Voice Features

### Speech Recognition
- **Natural Conversations**: Speak naturally, no keywords needed
- **Real-time Transcription**: See your words as you speak
- **Interim Results**: Visual feedback while speaking
- **Error Handling**: Graceful fallbacks

### Speech Synthesis
- **Natural Voice**: AI responds with human-like voice
- **Customizable**: Adjust speed, pitch, and voice
- **Mute Option**: Silent mode if needed
- **Quality Voices**: Best available system voices

### Voice Manager
```javascript
const voiceManager = new VoiceManager({
  onTranscript: (result) => console.log(result),
  onError: (error) => console.error(error),
  onStart: () => console.log('Listening...'),
  onEnd: () => console.log('Stopped')
});

// Start listening
voiceManager.startListening();

// Speak response
await voiceManager.speak('How are you feeling today?');
```

## ğŸ’¬ Conversation Flows

The app uses a **flow-based conversation system**:

### Initial Flow
```
"Hi, I'm PsyCoach. What's on your mind today?"
  â”œâ”€ "I'm feeling anxious" â†’ Anxiety Support Flow
  â”œâ”€ "I need to talk" â†’ Open Conversation
  â”œâ”€ "Show me tools" â†’ Tools Menu
  â””â”€ "Journal entry" â†’ Journal Flow
```

### Anxiety Support Flow
```
"I hear that you're feeling anxious..."
  â”œâ”€ "Try grounding" â†’ Grounding Exercise
  â”œâ”€ "Talk about it" â†’ Open Conversation
  â””â”€ "Go back" â†’ Initial Flow
```

### Custom Flows
```javascript
// Add your own flow
conversationFlow.flows.custom = {
  id: 'custom',
  message: 'Your custom message',
  options: [
    { text: 'Option 1', next: 'flow_id' },
    { text: 'Option 2', next: 'another_flow' }
  ]
};
```

## ğŸ¯ User Interface

### Voice Orb States
- **Idle** ğŸ™ï¸ - Ready to listen
- **Listening** ğŸ‘‚ - Recording your voice
- **Thinking** ğŸ¤” - Processing your message
- **Speaking** ğŸ—£ï¸ - AI is responding

### Action Cards
Quick-access options that appear based on conversation context:
- Visual button cards
- One-tap navigation
- Context-aware options

### Navigation Tabs
- **Voice** ğŸ¤ - Main voice interface
- **History** ğŸ’¬ - Conversation history
- **Journal** ğŸ“” - Journal entries
- **Tools** ğŸ§© - CBT and wellness tools
- **Insights** ğŸ“Š - Progress tracking

## âš™ï¸ Settings

Access via the settings button (âš™ï¸):

### Voice Settings
- **Voice Selection**: Choose from available system voices
- **Speech Rate**: 0.5x - 2.0x (default: 0.95x)
- **Pitch**: 0.5 - 2.0 (default: 1.0)
- **Volume**: 0.0 - 1.0 (default: 1.0)

Settings are automatically saved to localStorage.

## ğŸš€ Getting Started

### 1. Access the App
```bash
# Navigate to voice-first version
http://localhost:5173/index-voice.html

# Or use the landing page
http://localhost:5173/landing.html
```

### 2. Grant Microphone Permission
The browser will ask for microphone access. Click "Allow".

### 3. Start Talking
1. Tap the voice orb or main microphone button
2. Speak naturally
3. Wait for the AI response
4. Continue the conversation

### 4. Use Quick Actions
- Tap action cards for guided flows
- Use navigation tabs to switch modes
- Access settings for customization

## ğŸ¨ Styling

The voice interface uses a custom dark teal theme:

```css
/* Key Colors */
--bg-primary: #0d1e1c     /* Deep teal background */
--accent-teal: #3d7068    /* Primary accent */
--accent-gold: #c9a76d    /* Secondary accent */
--text-primary: #ffffff   /* White text */
```

### Customization
Edit `styles-voice.css` to customize:
- Colors (`:root` variables)
- Animations
- Spacing
- Border radius
- Typography

## ğŸ› ï¸ Technical Details

### Browser Support
- **Chrome/Edge**: âœ… Full support
- **Safari**: âœ… Full support (iOS 14+)
- **Firefox**: âš ï¸ Limited (no speech recognition)

### Required APIs
- **Web Speech API** (Speech Recognition)
- **Speech Synthesis API**
- **Web Audio API** (future enhancements)

### Performance
- Minimal latency (~100ms transcription)
- Smooth 60fps animations
- Lightweight bundle (~50KB gzipped)

## ğŸ“± Mobile Experience

Optimized for mobile devices:
- Touch-friendly controls
- Responsive layout (max-width: 480px)
- Native speech recognition on iOS/Android
- PWA-ready

## ğŸ” Privacy

Voice data:
- âœ… Processed locally in browser
- âœ… Not sent to external servers (in mock mode)
- âœ… Not recorded or stored
- âœ… Settings saved in localStorage only

## ğŸ§ª Testing Voice Features

### Test Scenarios

1. **Basic Conversation**
   - Say: "I'm feeling anxious"
   - Expect: Empathetic response + options

2. **Voice Settings**
   - Open settings
   - Change voice/rate/pitch
   - Test with "Hello, this is a test"

3. **Mute Mode**
   - Toggle mute
   - Verify no audio output
   - Transcription still works

4. **Error Handling**
   - Deny microphone permission
   - See graceful error message
   - Fallback options available

## ğŸ”„ Integration with AI

When you integrate real AI (Vercel AI SDK):

```javascript
// In app-voice.js
async function processUserMessage(message) {
  // Process through agent with voice context
  const response = await agent.processMessage(message, {
    mode: 'voice',
    preferredLength: 'short' // Voice responses should be concise
  });

  // Speak the response
  await voiceManager.speak(response.content);
}
```

### Voice-Optimized Responses
```javascript
// In agent.js - system prompt
const voiceSystemPrompt = `
You are PsyCoach's voice interface. Keep responses:
- Concise (2-3 sentences max)
- Natural and conversational
- Easy to speak aloud
- Empathetic and supportive
Avoid: long lists, complex formatting, excessive detail.
`;
```

## ğŸ“Š Future Enhancements

### Planned Features
- [ ] Voice emotion detection
- [ ] Breathing exercise guidance
- [ ] Voice journaling
- [ ] Multi-language support
- [ ] Voice biometrics for stress detection
- [ ] Ambient sound integration
- [ ] Offline mode with cache

### Advanced Voice
- [ ] Voice cloning for consistent AI voice
- [ ] Interrupt handling (stop AI mid-speech)
- [ ] Conversation summaries
- [ ] Voice shortcuts/commands

## ğŸ“ Best Practices

### For Users
1. **Quiet Environment**: Use in quiet space for best recognition
2. **Clear Speech**: Speak clearly and at normal pace
3. **Pause Between Thoughts**: Give AI time to process
4. **Use Headphones**: Better audio quality and privacy

### For Developers
1. **Short Responses**: Keep AI responses under 30 seconds
2. **Error Boundaries**: Always have fallback flows
3. **Progressive Enhancement**: Work without voice too
4. **Test on Real Devices**: Desktop â‰  mobile voice quality

## ğŸ› Troubleshooting

### Microphone Not Working
- Check browser permissions
- Try HTTPS (required for some browsers)
- Test in Chrome/Safari
- Check system microphone settings

### Poor Recognition
- Reduce background noise
- Speak more clearly
- Check microphone quality
- Try different browser

### AI Not Speaking
- Check mute button
- Verify browser supports speech synthesis
- Check volume settings
- Try different voice in settings

### Slow Responses
- Check network connection (when using real AI)
- Reduce speech rate in settings
- Clear browser cache
- Restart browser

## ğŸ“ Support Resources

For voice-related issues:
1. Check browser console for errors
2. Verify microphone permissions
3. Test with simple phrases first
4. Review `ARCHITECTURE.md` for technical details

---

**Voice-First Mental Health Support** ğŸ™ï¸ğŸ’š

Natural conversations for better mental wellness.

